# .env.example

# --- Required API Keys ---
GOOGLE_GEMINI_API_KEY="YOUR_GEMINI_API_KEY_GOES_HERE"


# --- LLM Configuration ---
LLM_PRIORITY="gemini,local"

# Defines the local models to try, in comma-separated order.
# These model names must match what you have downloaded in Ollama.
LOCAL_LLM_MODELS="llama3,mistral"
